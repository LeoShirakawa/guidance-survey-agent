from app.tools.search_tool import search_discovery_engine
from vertexai.generative_models import GenerativeModel
import json
from io import BytesIO
import base64
import re
import os
import pandas as pd
import docx
from pypdf import PdfReader
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A4
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.cidfonts import UnicodeCIDFont
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Table, TableStyle
from reportlab.lib import colors

# --- Configuration ---
EVALUATOR_MODEL_NAME = "gemini-2.5-pro"

def clean_markdown(text):
    """Removes common markdown formatting."""
    text = re.sub(r'###\s?', '', text)
    text = re.sub(r'\*\*', '', text)
    text = re.sub(r'\*', '', text)
    text = re.sub(r'üìà|üìâ|üéØ', '', text) # Remove emojis
    return text.strip()

class ReportParserAgent:
    """
    Agent responsible for parsing the user-uploaded report.
    """
    def run(self, file_content: bytes, file_name: str) -> str:
        print(f"Running Report Parser Agent for file: {file_name}")
        _, extension = os.path.splitext(file_name)
        text = ""
        try:
            if extension == '.pdf':
                reader = PdfReader(BytesIO(file_content))
                for page in reader.pages:
                    text += page.extract_text() + "\n"
            elif extension == '.docx':
                doc = docx.Document(BytesIO(file_content))
                for para in doc.paragraphs:
                    text += para.text + "\n"
            elif extension == '.xlsx':
                df = pd.read_excel(BytesIO(file_content))
                text = df.to_string()
            elif extension == '.csv':
                text = pd.read_csv(BytesIO(file_content)).to_string()
            elif extension == '.txt':
                text = file_content.decode('utf-8')
            else:
                return f"„Çµ„Éù„Éº„Éà„Åï„Çå„Å¶„ÅÑ„Å™„ÅÑ„Éï„Ç°„Ç§„É´ÂΩ¢Âºè„Åß„Åô: {extension}"
            return text
        except Exception as e:
            print(f"Error parsing file {file_name}: {e}")
            return f"„Éï„Ç°„Ç§„É´„ÅÆËß£Êûê‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}"


class GuidanceRetrieverAgent:
    """
    Agent responsible for retrieving relevant guidance from Discovery Engine.
    """
    def run(self, query: str) -> dict:
        print(f"Running Guidance Retriever Agent with query: {query}")
        return search_discovery_engine(query)


class ComplianceEvaluatorAgent:
    """
    Agent responsible for evaluating the report against the retrieved guidance.
    """
    def __init__(self):
        self.model = GenerativeModel(EVALUATOR_MODEL_NAME)

    def run(self, report_text: str, retrieved_data: dict) -> list:
        """
        Compares the report against the guidance and generates a structured evaluation table.
        """
        print("Running Compliance Evaluator Agent...")
        guidance_context = retrieved_data.get("context", "„Ç¨„Ç§„ÉÄ„É≥„Çπ„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì„Åß„Åó„Åü„ÄÇ")
        citations = retrieved_data.get("citations", [])
        citation_text = "\n".join([f"- {c.get('title', 'N/A')} (Page: {c.get('page_number', 'N/A')}, URI: {c.get('uri', 'N/A')})" for c in citations])
        if not citation_text:
            citation_text = "„Å™„Åó"

        evaluation_prompt = f"""
        „ÅÇ„Å™„Åü„ÅØ„ÄÅ‰ºÅÊ•≠„ÅÆ„Çµ„Çπ„ÉÜ„Éä„Éì„É™„ÉÜ„Ç£„É¨„Éù„Éº„Éà„ÇíTNFD„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ„Å´Âü∫„Å•„ÅçË©ï‰æ°„Åô„Çã„ÄÅ‰∏ñÁïå„Éà„ÉÉ„Éó„ÇØ„É©„Çπ„ÅÆÂ∞ÇÈñÄ„Ç¢„Éä„É™„Çπ„Éà„Åß„Åô„ÄÇ
        ‰ª•‰∏ã„ÅÆ„ÄåË©ï‰æ°ÂØæË±°„É¨„Éù„Éº„Éà„Äç„Çí„ÄÅ„ÄåÂèÇÁÖß„Ç¨„Ç§„ÉÄ„É≥„Çπ„Äç„Åä„Çà„Å≥„ÄåÂèÇÁÖßÂÖÉ„Éâ„Ç≠„É•„É°„É≥„Éà„Äç„Å®ÂæπÂ∫ïÁöÑ„Å´ÊØîËºÉÂàÜÊûê„Åó„ÄÅTNFD„ÅåË¶ÅÊ±Ç„Åô„Çã„Äå14„ÅÆÈñãÁ§∫Êé®Â•®È†ÖÁõÆ„Äç„ÅÆ„Åù„Çå„Åû„Çå„Å´„Å§„ÅÑ„Å¶„ÄÅË©ï‰æ°ÁµêÊûú„ÇíJSONÂΩ¢Âºè„ÅßÂá∫Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

        **ÂèÇÁÖß„Ç¨„Ç§„ÉÄ„É≥„Çπ (Vertex AI Search„Å´„Çà„ÇãÊ§úÁ¥¢ÁµêÊûú):**
        ---
        {guidance_context}
        ---
        **ÂèÇÁÖßÂÖÉ„Éâ„Ç≠„É•„É°„É≥„Éà:**
        ---
        {citation_text}
        ---
        **Ë©ï‰æ°ÂØæË±°„É¨„Éù„Éº„Éà:**
        ---
        {report_text}
        ---

        **Ë©ï‰æ°„Å®Âá∫Âäõ„ÅÆË¶Å‰ª∂:**
        ‰ª•‰∏ã„ÅÆ14È†ÖÁõÆ„Åô„Åπ„Å¶„Å´„Å§„ÅÑ„Å¶„ÄÅË©ï‰æ°„ÇíÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
        1.  **„Ç¨„Éê„Éä„É≥„Çπ - A. ÂèñÁ∑†ÂΩπ‰ºö„ÅÆÁõ£Áù£**: Ëá™ÁÑ∂Èñ¢ÈÄ£Ë™≤È°å„Å´Èñ¢„Åô„ÇãÂèñÁ∑†ÂΩπ‰ºö„ÅÆÁõ£Áù£‰ΩìÂà∂
        2.  **„Ç¨„Éê„Éä„É≥„Çπ - B. ÁµåÂñ∂ËÄÖ„ÅÆÂΩπÂâ≤**: ÁµåÂñ∂ËÄÖ„ÅÆÂΩπÂâ≤„Å®Â†±Âëä‰ΩìÂà∂
        3.  **„Ç¨„Éê„Éä„É≥„Çπ - C. ‰∫∫Ê®©ÊñπÈáù„Å®„Çπ„ÉÜ„Éº„ÇØ„Éõ„É´„ÉÄ„Éº„Éª„Ç®„É≥„Ç≤„Éº„Ç∏„É°„É≥„Éà**: ‰∫∫Ê®©ÊñπÈáù„Å®„Ç®„É≥„Ç≤„Éº„Ç∏„É°„É≥„ÉàÊ¥ªÂãï
        4.  **Êà¶Áï• - A. Áü≠Êúü„Éª‰∏≠Êúü„ÉªÈï∑Êúü„ÅÆËá™ÁÑ∂Èñ¢ÈÄ£Ë™≤È°å**: ÊúüÈñì„Åî„Å®„ÅÆ„É™„Çπ„ÇØ„Å®Ê©ü‰ºö
        5.  **Êà¶Áï• - B. „Éì„Ç∏„Éç„Çπ„É¢„Éá„É´Á≠â„Å∏„ÅÆ„Ç§„É≥„Éë„ÇØ„Éà**: „Éì„Ç∏„Éç„Çπ„É¢„Éá„É´„ÄÅ„Éê„É™„É•„Éº„ÉÅ„Çß„Éº„É≥„ÄÅÊà¶Áï•„ÄÅË≤°ÂãôË®àÁîª„Å∏„ÅÆÂΩ±Èüø
        6.  **Êà¶Áï• - C. Êà¶Áï•„ÅÆ„É¨„Ç∏„É™„Ç®„É≥„Çπ**: „Ç∑„Éä„É™„Ç™ÂàÜÊûê„ÇíËÄÉÊÖÆ„Åó„ÅüÊà¶Áï•„ÅÆÂº∑Èù≠ÊÄß
        7.  **Êà¶Áï• - D. ÂÑ™ÂÖàÂú∞Âüü**: ÂÑ™ÂÖàÂú∞Âüü„Å´„Åä„Åë„ÇãË≥áÁî£„ÇÑÊ¥ªÂãï„ÅÆÂ†¥ÊâÄ
        8.  **„É™„Çπ„ÇØ„Å®„Ç§„É≥„Éë„ÇØ„Éà„ÅÆÁÆ°ÁêÜ - A(i). Áõ¥Êé•ÊìçÊ•≠„Å´„Åä„Åë„Çã„Éó„É≠„Çª„Çπ**: Áõ¥Êé•ÊìçÊ•≠„Å´„Åä„Åë„ÇãÁâπÂÆö„ÉªË©ï‰æ°„ÉªÂÑ™ÂÖàÈ†Ü‰Ωç‰ªò„Åë„ÅÆ„Éó„É≠„Çª„Çπ
        9.  **„É™„Çπ„ÇØ„Å®„Ç§„É≥„Éë„ÇØ„Éà„ÅÆÁÆ°ÁêÜ - A(ii). „Éê„É™„É•„Éº„ÉÅ„Çß„Éº„É≥„Å´„Åä„Åë„Çã„Éó„É≠„Çª„Çπ**: „Éê„É™„É•„Éº„ÉÅ„Çß„Éº„É≥„Å´„Åä„Åë„ÇãÁâπÂÆö„ÉªË©ï‰æ°„ÉªÂÑ™ÂÖàÈ†Ü‰Ωç‰ªò„Åë„ÅÆ„Éó„É≠„Çª„Çπ
        10. **„É™„Çπ„ÇØ„Å®„Ç§„É≥„Éë„ÇØ„Éà„ÅÆÁÆ°ÁêÜ - B. ÁÆ°ÁêÜ„Åô„Çã„Åü„ÇÅ„ÅÆ„Éó„É≠„Çª„Çπ**: „É™„Çπ„ÇØ„Å®Ê©ü‰ºö„ÇíÁÆ°ÁêÜ„Åô„Çã„Éó„É≠„Çª„Çπ
        11. **„É™„Çπ„ÇØ„Å®„Ç§„É≥„Éë„ÇØ„Éà„ÅÆÁÆ°ÁêÜ - C. ÂÖ®‰Ωì„É™„Çπ„ÇØÁÆ°ÁêÜ„Å∏„ÅÆÁµ±Âêà**: ÂÖ®Á§æÁöÑ„É™„Çπ„ÇØÁÆ°ÁêÜ„Å∏„ÅÆÁµ±Âêà
        12. **Ê∏¨ÂÆöÊåáÊ®ô„Å®„Çø„Éº„Ç≤„ÉÉ„Éà - A. „É™„Çπ„ÇØ„Å®Ê©ü‰ºö„ÇíË©ï‰æ°„ÉªÁÆ°ÁêÜ„Åô„Çã„Åü„ÇÅ„ÅÆÊ∏¨ÂÆöÊåáÊ®ô**: „É™„Çπ„ÇØ„Å®Ê©ü‰ºö„Å´Èñ¢„Åô„ÇãÊ∏¨ÂÆöÊåáÊ®ô
        13. **Ê∏¨ÂÆöÊåáÊ®ô„Å®„Çø„Éº„Ç≤„ÉÉ„Éà - B. ‰æùÂ≠ò„Å®„Ç§„É≥„Éë„ÇØ„Éà„ÇíË©ï‰æ°„ÉªÁÆ°ÁêÜ„Åô„Çã„Åü„ÇÅ„ÅÆÊ∏¨ÂÆöÊåáÊ®ô**: ‰æùÂ≠ò„Å®„Ç§„É≥„Éë„ÇØ„Éà„Å´Èñ¢„Åô„ÇãÊ∏¨ÂÆöÊåáÊ®ô
        14. **Ê∏¨ÂÆöÊåáÊ®ô„Å®„Çø„Éº„Ç≤„ÉÉ„Éà - C. „Çø„Éº„Ç≤„ÉÉ„Éà„Å®ÁõÆÊ®ô„ÄÅ„Åä„Çà„Å≥ÂÆüÁ∏æ**: Ë®≠ÂÆö„Åó„ÅüÁõÆÊ®ô„Å®ÂÆüÁ∏æ

        **Âá∫ÂäõÂΩ¢Âºè**:
        ÂøÖ„Åö‰ª•‰∏ã„ÅÆJSONÂΩ¢Âºè„ÅÆ„É™„Çπ„Éà„ÅßÂá∫Âäõ„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ‰ªñ„ÅÆ„ÉÜ„Ç≠„Çπ„Éà„ÅØ‰∏ÄÂàáÂê´„ÇÅ„Å™„ÅÑ„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ
        ÂêÑÈ†ÖÁõÆ„ÅÆ`reference`„Éï„Ç£„Éº„É´„Éâ„Å´„ÅØ„ÄÅ**„ÄåÂèÇÁÖßÂÖÉ„Éâ„Ç≠„É•„É°„É≥„Éà„Äç„É™„Çπ„Éà„ÅÆ‰∏≠„Åã„Çâ„ÄÅ„Åù„ÅÆË©ï‰æ°„ÅÆÊ†πÊã†„Å®„Åó„Å¶ÊúÄ„ÇÇÈñ¢ÈÄ£ÊÄß„ÅÆÈ´ò„ÅÑ„ÇÇ„ÅÆ„Çí1„Å§„Å†„ÅëÈÅ∏„Å≥„ÄÅ„Åù„ÅÆ„Çø„Ç§„Éà„É´„Å®„Éö„Éº„Ç∏Áï™Âè∑„ÇíË®òËø∞„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ**
        ```json
        [
          {{
            "classification": "„Ç¨„Éê„Éä„É≥„Çπ",
            "item": "A. ÂèñÁ∑†ÂΩπ‰ºö„ÅÆÁõ£Áù£",
            "score": "4.2/5.0",
            "good_point": "ÂÑ™„Çå„Å¶„ÅÑ„ÇãÁÇπ„ÇíÂÖ∑‰ΩìÁöÑ„Å´Ë®òËø∞",
            "improvement_point": "‰∏çË∂≥„Åó„Å¶„ÅÑ„ÇãÁÇπ„ÇÑÊîπÂñÑÁÇπ„ÇíÂÖ∑‰ΩìÁöÑ„Å´ÊåáÊëò",
            "reference": "„Çø„Ç§„Éà„É´ (Page: „Éö„Éº„Ç∏Áï™Âè∑)"
          }}
        ]
        ```
        """
        try:
            response = self.model.generate_content(contents=[evaluation_prompt])
            json_text = response.text.strip().replace("```json", "").replace("```", "")
            evaluation_list = json.loads(json_text)
            # Clean markdown from generated text
            for item in evaluation_list:
                item["good_point"] = clean_markdown(item.get("good_point", ""))
                item["improvement_point"] = clean_markdown(item.get("improvement_point", ""))
            return evaluation_list
        except Exception as e:
            print(f"Error during compliance evaluation: {e}")
            return [{"classification": "„Ç®„É©„Éº", "item": "Ë©ï‰æ°„Ç®„É©„Éº", "score": "0/5.0", "good_point": "N/A", "improvement_point": f"LLM„Å´„Çà„ÇãË©ï‰æ°‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}", "reference": "N/A"}]

class SynthesisAgent:
    """
    Agent that synthesizes the evaluation results, calculates average scores, and provides a summary.
    """
    def __init__(self):
        self.model = GenerativeModel(EVALUATOR_MODEL_NAME)

    def run(self, evaluation_table: list) -> dict:
        print("Running Synthesis Agent...")
        scores = {}
        total_score = 0
        total_count = 0
        for row in evaluation_table:
            classification = row.get("classification")
            try:
                score_str = str(row.get("score", "0/5.0")).split('/')[0]
                score = float(score_str)
                if classification not in scores:
                    scores[classification] = []
                scores[classification].append(score)
                total_score += score
                total_count += 1
            except (ValueError, IndexError):
                continue

        avg_scores = {cls: sum(s) / len(s) for cls, s in scores.items() if s}
        overall_avg = total_score / total_count if total_count > 0 else 0
        
        summary_prompt = f"""
        „ÅÇ„Å™„Åü„ÅØË©ï‰æ°ÁµêÊûú„Çí„Ç§„É≥„Éï„Ç©„Ç∞„É©„Éï„Ç£„ÉÉ„ÇØ„Å´„Åæ„Å®„ÇÅ„Çã„Éá„Ç∂„Ç§„Éä„Éº„Åß„Åô„ÄÇ
        ‰ª•‰∏ã„ÅÆË©ï‰æ°ÁµêÊûú„ÅÆÂπ≥ÂùáÁÇπ„Å®ÂÜÖÂÆπ„ÇíÂü∫„Å´„ÄÅ„É¨„Éù„Éº„ÉàÂÖ®‰Ωì„ÅÆÁ∑èÊã¨„Ç≥„É°„É≥„Éà„ÇíÁîüÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

        **Á∑èÂêàÂπ≥ÂùáÁÇπ:** {overall_avg:.2f} / 5.0
        **ÂàÜÈ°ûÂà•Âπ≥Âùá„Çπ„Ç≥„Ç¢:**
        {json.dumps(avg_scores, indent=2, ensure_ascii=False)}

        **„Çø„Çπ„ÇØ:**
        „É¨„Éù„Éº„ÉàÂÖ®‰Ωì„ÅÆÂº∑„Åø„Å®Âº±„Åø„Çí„ÄÅÁµµÊñáÂ≠ó„Çí‰Ωø„Å£„Å¶Ë¶ñË¶öÁöÑ„Å´ÂàÜ„Åã„Çä„ÇÑ„Åô„Åè„ÄÅË©≥Á¥∞„Å´ÂàÜÊûê„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
        „Åù„ÅÆ‰∏ä„Åß„ÄÅ‰ªäÂæå„ÅÆÊîπÂñÑ„Å´Âêë„Åë„ÅüÂÖ∑‰ΩìÁöÑ„Å™„Ç¢„ÇØ„Ç∑„Éß„É≥„Éó„É©„É≥„Çí3„Å§ÊèêË®Ä„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
        „Ç¢„Ç¶„Éà„Éó„ÉÉ„Éà„ÅØ‰ª•‰∏ã„ÅÆÂΩ¢Âºè„Å´Âæì„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

        ---
        ### Á∑èÂêàË©ï‰æ°: {overall_avg:.2f} / 5.0

        ### üìà **Á∑èÂêàÁöÑ„Å™Âº∑„Åø (Strength)**
        [„Åì„Åì„Å´„É¨„Éù„Éº„ÉàÂÖ®‰Ωì„ÅßÂÑ™„Çå„Å¶„ÅÑ„ÇãÁÇπ„ÇíË©≥Á¥∞„Å´Ë®òËø∞]

        ### üìâ **‰ªäÂæå„ÅÆË™≤È°å (Weakness)**
        [„Åì„Åì„Å´„É¨„Éù„Éº„ÉàÂÖ®‰Ωì„ÅßÊîπÂñÑ„ÅåÂøÖË¶Å„Å™ÁÇπ„ÇíË©≥Á¥∞„Å´Ë®òËø∞]

        ### üéØ **Êé®Â•®„Ç¢„ÇØ„Ç∑„Éß„É≥„Éó„É©„É≥ (Action Plan)**
        1.  **[„Ç¢„ÇØ„Ç∑„Éß„É≥1„ÅÆ„Çø„Ç§„Éà„É´]**: [„Ç¢„ÇØ„Ç∑„Éß„É≥1„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÂÜÖÂÆπ]
        2.  **[„Ç¢„ÇØ„Ç∑„Éß„É≥2„ÅÆ„Çø„Ç§„Éà„É´]**: [„Ç¢„ÇØ„Ç∑„Éß„É≥2„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÂÜÖÂÆπ]
        3.  **[„Ç¢„ÇØ„Ç∑„Éß„É≥3„ÅÆ„Çø„Ç§„Éà„É´]**: [„Ç¢„ÇØ„Ç∑„Éß„É≥3„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÂÜÖÂÆπ]
        ---
        """
        try:
            response = self.model.generate_content(contents=[summary_prompt])
            summary_text = clean_markdown(response.text)
        except Exception as e:
            print(f"Error during summary generation: {e}")
            summary_text = f"Á∑èÊã¨„Ç≥„É°„É≥„Éà„ÅÆÁîüÊàê‰∏≠„Å´„Ç®„É©„Éº„ÅåÁô∫Áîü„Åó„Åæ„Åó„Åü: {e}"

        return {
            "average_scores": avg_scores,
            "summary_comment": summary_text
        }

class RadarChartAgent:
    """
    Agent that generates data for a radar chart.
    """
    def run(self, average_scores: dict) -> dict:
        print("Running Radar Chart Agent...")
        return {
            "labels": list(average_scores.keys()),
            "data": list(average_scores.values())
        }

class PdfGeneratorAgent:
    """
    Agent that generates a PDF report from the evaluation results.
    """
    def run(self, final_result: dict) -> str:
        print("Running PDF Generator Agent...")
        try:
            buffer = BytesIO()
            
            # Register Japanese font
            pdfmetrics.registerFont(UnicodeCIDFont('HeiseiMin-W3'))
            
            styles = getSampleStyleSheet()
            styles.add(ParagraphStyle(name='Japanese', fontName='HeiseiMin-W3', fontSize=10, leading=14))
            styles.add(ParagraphStyle(name='Japanese-h1', parent=styles['h1'], fontName='HeiseiMin-W3'))
            styles.add(ParagraphStyle(name='Japanese-h2', parent=styles['h2'], fontName='HeiseiMin-W3'))

            story = []
            
            story.append(Paragraph("TNFD„É¨„Éù„Éº„ÉàË©ï‰æ°ÁµêÊûú", styles['Japanese-h1']))
            story.append(Spacer(1, 12))

            # Summary
            story.append(Paragraph("Á∑èÂêàË©ï‰æ°", styles['Japanese-h2']))
            summary_text = final_result.get("synthesis", {}).get("summary_comment", "N/A")
            story.append(Paragraph(summary_text.replace("\n", "<br/>"), styles['Japanese']))
            story.append(Spacer(1, 24))

            # Evaluation Table
            story.append(Paragraph("Ë©≥Á¥∞Ë©ï‰æ°", styles['Japanese-h2']))
            table_data = [['È†ÖÁõÆ', 'Ë©ï‰æ°', 'ËâØ„ÅÑÁÇπ', 'ÊîπÂñÑÁÇπ', 'ÂèÇËÄÉÊñáÁåÆ']]
            for row in final_result.get("evaluation_table", []):
                table_data.append([
                    Paragraph(row.get("item", ""), styles['Japanese']),
                    Paragraph(str(row.get("score", "")), styles['Japanese']),
                    Paragraph(row.get("good_point", ""), styles['Japanese']),
                    Paragraph(row.get("improvement_point", ""), styles['Japanese']),
                    Paragraph(row.get("reference", ""), styles['Japanese']),
                ])
            
            table = Table(table_data, colWidths=[60, 40, 120, 120, 120])
            table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.grey),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.whitesmoke),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),
                ('FONTNAME', (0, 0), (-1, 0), 'HeiseiMin-W3'),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.beige),
                ('GRID', (0,0), (-1,-1), 1, colors.black)
            ]))
            story.append(table)
            
            doc = SimpleDocTemplate(buffer, pagesize=A4)
            doc.build(story)
            
            pdf_bytes = buffer.getvalue()
            buffer.close()
            return base64.b64encode(pdf_bytes).decode('utf-8')

        except Exception as e:
            print(f"Error generating PDF: {e}")
            return ""
